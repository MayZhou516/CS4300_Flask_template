{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /usr/local/lib/python2.7/site-packages\n",
      "Requirement already satisfied: dill<0.3,>=0.2 in /usr/local/lib/python2.7/site-packages (from spacy)\n",
      "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python2.7/site-packages (from spacy)\n",
      "Requirement already satisfied: murmurhash<0.29,>=0.28 in /usr/local/lib/python2.7/site-packages (from spacy)\n",
      "Requirement already satisfied: preshed<2.0.0,>=1.0.0 in /usr/local/lib/python2.7/site-packages (from spacy)\n",
      "Requirement already satisfied: pathlib in /usr/local/lib/python2.7/site-packages (from spacy)\n",
      "Requirement already satisfied: thinc<6.11.0,>=6.10.1 in /usr/local/lib/python2.7/site-packages (from spacy)\n",
      "Requirement already satisfied: cymem<1.32,>=1.30 in /usr/local/lib/python2.7/site-packages (from spacy)\n",
      "Requirement already satisfied: regex==2017.4.5 in /usr/local/lib/python2.7/site-packages (from spacy)\n",
      "Requirement already satisfied: ujson>=1.35 in /usr/local/lib/python2.7/site-packages (from spacy)\n",
      "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python2.7/site-packages (from spacy)\n",
      "Requirement already satisfied: cytoolz<0.9,>=0.8 in /usr/local/lib/python2.7/site-packages (from thinc<6.11.0,>=6.10.1->spacy)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python2.7/site-packages (from thinc<6.11.0,>=6.10.1->spacy)\n",
      "Requirement already satisfied: six<2.0.0,>=1.10.0 in /usr/local/lib/python2.7/site-packages (from thinc<6.11.0,>=6.10.1->spacy)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python2.7/site-packages (from thinc<6.11.0,>=6.10.1->spacy)\n",
      "Requirement already satisfied: msgpack-python in /usr/local/lib/python2.7/site-packages (from thinc<6.11.0,>=6.10.1->spacy)\n",
      "Requirement already satisfied: msgpack-numpy==0.4.1 in /usr/local/lib/python2.7/site-packages (from thinc<6.11.0,>=6.10.1->spacy)\n",
      "Requirement already satisfied: termcolor in /usr/local/lib/python2.7/site-packages (from thinc<6.11.0,>=6.10.1->spacy)\n",
      "Requirement already satisfied: toolz>=0.8.0 in /usr/local/lib/python2.7/site-packages (from cytoolz<0.9,>=0.8->thinc<6.11.0,>=6.10.1->spacy)\n",
      "\u001b[33mYou are using pip version 9.0.3, however version 10.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python2.7/site-packages\n",
      "Requirement already satisfied: six in /usr/local/lib/python2.7/site-packages (from nltk)\n",
      "\u001b[33mYou are using pip version 9.0.3, however version 10.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install spacy\n",
    "!{sys.executable} -m pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/Pegah/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# the imports used in A2\n",
    "import re\n",
    "# import json\n",
    "from glob import glob\n",
    "import os\n",
    "from io import StringIO\n",
    "from itertools import groupby\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "# import bs4\n",
    "# %matplotlib inline\n",
    "# import matplotlib.pyplot as plt\n",
    "# Imports that might help with various functionality\n",
    "import functools\n",
    "import operator\n",
    "\n",
    "# Additional imports from A3\n",
    "from __future__ import print_function\n",
    "import math\n",
    "from collections import defaultdict\n",
    "# from nltk.tokenize import TreebankWordTokenizer\n",
    "# import Levenshtein  # package python-Levenshtein\n",
    "\n",
    "# Additional imports from A5\n",
    "import nltk\n",
    "# nltk.download()\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import cPickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do not run these 2 blocks -- Pickling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPACY package\n",
    "import spacy\n",
    "# nlp = spacy.load('en')\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"nlp.pickle\", \"wb+\") as f:\n",
    "    pickle.dump(nlp, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run this instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: 'nlp.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-e47a303c2746>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpkl_nlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'nlp.pickle'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpkl_nlp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: 'nlp.pickle'"
     ]
    }
   ],
   "source": [
    "pkl_nlp = open('nlp.pickle', 'rb')\n",
    "nlp = pickle.load(pkl_nlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each woman's entry is a dictionary with the following keys...\n",
      "[u'url', u'views', u'name', u'summary']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open(\"data.json\", \"r\") as f:\n",
    "    women_summaries = json.load(f)\n",
    "\n",
    "print(\"Each woman's entry is a dictionary with the following keys...\")\n",
    "print(women_summaries[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMOVED FROM SPACY VERSION\n",
    "# creates a list of women to keep as a global variable\n",
    "women_names = list()\n",
    "for i in range(len(women_summaries)):\n",
    "    name = women_summaries[i]['name']\n",
    "    end_index = name.find('(')\n",
    "    if end_index != -1 and name[: (end_index-1)] not in women_names :\n",
    "        women_names.append(name[: (end_index-1)])\n",
    "    elif end_index == -1 and name not in women_names :\n",
    "        women_names.append(name)\n",
    "        \n",
    "# print(women_names)\n",
    "# women_names is a list of the names of women in order of the JSON file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deduplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_names = []\n",
    "deduped_women = list(women_summaries)\n",
    "for woman in deduped_women:\n",
    "    if woman['name'] not in check_names:\n",
    "        check_names.append(woman['name'])\n",
    "    else:\n",
    "        deduped_women.remove(woman)\n",
    "import pickle\n",
    "pickle.dump(deduped_women, open( \"deduped_women.pickle\", \"wb\" ), protocol=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spacy Dictionary\n",
    "For building token dictionary for W2W matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Builds a dictionary that maps woman to the list of tokens associated with her\n",
    "# {'woman1' : ['token1', 'token2', ... 'tokenn']}\n",
    "def build_spacy_token_dictionary(input_summaries, input_women_names):\n",
    "    # Builds a dictionary that maps each woman to their tokenized words (yes we've already done this but we want the spacy version)\n",
    "    women_token_dictionary = dict()\n",
    "    \n",
    "    for i in range(len(input_women_names)):\n",
    "        name = input_women_names[i]\n",
    "        summary = input_summaries[i]['summary']\n",
    "    \n",
    "        index_was = summary.find('was ')\n",
    "        index_is = summary.find('is ')\n",
    "        index_currently = summary.find('currently ')\n",
    "        if (index_was == -1 and index_is == -1):\n",
    "            summary2 = summary[index_currently:]\n",
    "        elif (index_was == -1 and index_currently == -1):\n",
    "            summary2 = summary[index_is:]\n",
    "        elif (index_is == -1 and index_currently == -1):\n",
    "            summary2 = summary[index_was:]\n",
    "        else :\n",
    "            index_min = min(index_is, index_was)\n",
    "            summary2 = summary[index_min:]\n",
    "            \n",
    "        # lowercase long string of summary\n",
    "        summary_lower = summary2.lower()\n",
    "        # doc object type\n",
    "        summary_nlp = nlp(summary_lower)\n",
    "        # type list\n",
    "        summary_list = [token.text for token in summary_nlp]\n",
    "        # type list, but without stop words\n",
    "        summary_token_filtered = [w for w in summary_list if w not in stopwords.words('english')]\n",
    "        \n",
    "        # convert to a string separated by spaces\n",
    "        summary_str = \" \".join(summary_token_filtered) \n",
    "        summary_nlp = nlp(summary_str)\n",
    "        women_token_dictionary[name] = summary_nlp\n",
    "    \n",
    "#     print(women_token_dictionary)\n",
    "    return women_token_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMMENTED OUT BECAUSE TOKENIZER DOES THIS\n",
    "women_token_dictionary = build_spacy_token_dictionary(women_summaries, women_names)\n",
    "# # print(women_token_dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF Vectorizer\n",
    "#### Includes pickling the vectorizer and the TF-IDF matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\", max_df = 0.95)\n",
    "matx = vectorizer.fit_transform(map(lambda x: x[\"summary\"], deduped_women))\n",
    "\n",
    "import pickle\n",
    "with open(\"myvectorizer.pickle\", \"wb+\") as f:\n",
    "    pickle.dump(vectorizer, f)\n",
    "    pickle.dump(matx, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spacy Similarity Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_sim_matrix(input_token_dictionary, input_len_names, input_women_names):\n",
    "    # Builds matrix using spacy that stores each woman's cosine similarity to each other\n",
    "    \n",
    "    sim_matrix = np.zeros(shape = (input_len_names, input_len_names))\n",
    "    \n",
    "    for woman1 in input_token_dictionary:\n",
    "        for woman2 in input_token_dictionary:\n",
    "            woman1_index = input_women_names.index(woman1)\n",
    "            woman2_index = input_women_names.index(woman2)\n",
    "#             print(input_token_dictionary[woman1])\n",
    "#             print(input_token_dictionary[woman2])\n",
    "            sim_matrix[woman1_index][woman2_index] = input_token_dictionary[woman1].similarity(input_token_dictionary[woman2])\n",
    "    np.fill_diagonal(sim_matrix, 0)\n",
    "    \n",
    "    return sim_matrix\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "women2women_cosine_sim_matrix = build_sim_matrix(women_token_dictionary, len(women_names), women_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "# Code taken from A5\n",
    "def get_ranked_women(input_woman, input_sim_matrix, input_women_names) :\n",
    "#     print(input_sim_matrix)\n",
    "    '''Return sorted rankings (most to least similar) of women as \n",
    "        a list of two-element tuples, where the first element is the \n",
    "        woman's name and the second element is the similarity score\n",
    "    '''\n",
    "    \n",
    "    # Get index from woman's name\n",
    "    idx = input_women_names.index(input_woman)\n",
    "    \n",
    "    # Get list of similarity scores for woman\n",
    "    score_lst = input_sim_matrix[idx]\n",
    "    women_score_lst = [(input_women_names[index], score) for index, score in enumerate(score_lst)]\n",
    "    \n",
    "    # Do not account for woman herself in ranking\n",
    "    women_score_lst = women_score_lst[:idx] + women_score_lst[idx+1:]\n",
    "    \n",
    "    # Sort rankings by score (most similar to least similar)\n",
    "    women_score_lst = sorted(women_score_lst, key=lambda x: -x[1])\n",
    "    \n",
    "    # Only returning top 5!\n",
    "    return women_score_lst[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Builds a 'top 5 most similar' list of woman for every woman\n",
    "def create_top_5_dict_women(input_sim_mat, num_women, input_women_names):\n",
    "    women_top5 = {}\n",
    "    \n",
    "    # Loop through each woman\n",
    "    for woman in range(num_women):\n",
    "        similarity_list = get_ranked_women(input_women_names[woman], input_sim_mat, input_women_names)\n",
    "        similarity_list = [x[0] for x in similarity_list]\n",
    "        women_top5[input_women_names[woman]] = similarity_list\n",
    "        \n",
    "    return women_top5\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "top5_dict_women2women = create_top_5_dict_women(women2women_cosine_sim_matrix, len(women_names), women_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'Olabisi Ugbebor',\n",
       " u'Anne Greenbaum',\n",
       " u'H\\xe9l\\xe8ne Esnault',\n",
       " u'Anu\\u0161ka Ferligoj',\n",
       " u'Marina Ratner']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top5_dict_women2women['Rachel Kuske']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(top5_dict_women2women, open( \"top5_dict_women2women.pickle\", \"wb\" ), protocol=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query output for Cossim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Load from the pickle\n",
    "pkl_file = open('myvectorizer.pickle', 'rb')\n",
    "vectorizer = pickle.load(pkl_file)\n",
    "matx = pickle.load(pkl_file)\n",
    "\n",
    "def cossim_scores(vectorizer, matx, query, data_dict):\n",
    "    q_vec = vectorizer.transform([query])\n",
    "    sim_doc_scores = cosine_similarity(q_vec, matx)\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    This next block is commented out because we are changing this function to return cosine sim scores\n",
    "    '''\n",
    "#     sim_docs = np.argsort(sim_doc_scores.flatten())[::-1]\n",
    "#     return_docs = []\n",
    "#     for hit in sim_docs:\n",
    "#         if sim_doc_scores[0][hit] > 0:\n",
    "# #             print(sim_doc_scores[0][hit])\n",
    "#             return_docs.append(data_dict[hit])\n",
    "#     if len(return_docs)>30:\n",
    "#         return_docs = return_docs[:30]\n",
    "\n",
    "    '''\n",
    "    Alright! back to business\n",
    "    '''\n",
    "    return sim_doc_scores[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.615413260897817"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(cossim_scores(vectorizer, matx, u\"is a french biologist\", deduped_women))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making our Spacy Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">Important!</span>\n",
    "The next block takes a while to run, but it's been pickled! Don't run the next 2 code blocks. Instead, just compile spacy_sim and run the block after it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT RUN!!\n",
    "spacy_array = np.zeros((len(deduped_women),384))\n",
    "for index, woman in enumerate(deduped_women):\n",
    "#     print(index)\n",
    "    wom_vec = nlp(woman['summary']).vector\n",
    "    if len(wom_vec) != 384:\n",
    "        wom_vec = np.zeros(384)\n",
    "    spacy_array[index] = wom_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle here\n",
    "# DON'T RUN THIS EITHER!\n",
    "with open(\"spacyarray.pickle\", \"wb+\") as f:\n",
    "    pickle.dump(spacy_array, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacysim_scores(spacy_mat, query, data_dict):\n",
    "    '''\n",
    "    spacy_mat: numpy array of documents by spacy vectors\n",
    "    \n",
    "    query: query string\n",
    "    \n",
    "    RETURNS\n",
    "    \n",
    "    '''\n",
    "    q = nlp(query)\n",
    "    sim_scores = np.dot(spacy_mat, q.vector)/((np.linalg.norm(spacy_mat)*np.linalg.norm(q.vector))+1)\n",
    "    \n",
    "    '''\n",
    "    commenting out this next part because we are changing this to return sim scores\n",
    "    '''\n",
    "#     sim_docs = np.argsort(sim_scores)[::-1]\n",
    "#     return_docs = []\n",
    "#     for hit in sim_docs[0:30]:\n",
    "#         return_docs.append(data_dict[hit])\n",
    "\n",
    "    return sim_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00965427, 0.0090375 , 0.00945791, ..., 0.00960577, 0.01025465,\n",
       "       0.00958002])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pkl_file_spacy = open('spacyarray.pickle', 'rb')\n",
    "spacy_array = pickle.load(pkl_file_spacy)\n",
    "\n",
    "spacysim_scores(spacy_array, u\"won the nobel prize\", deduped_women)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining our sim measures\n",
    "Spacy similarity scores + cosine similarity scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_query(cossim_arr, spacysim_arr, data_dict):\n",
    "    '''\n",
    "    cossim_arr : 1D array of cosine similarity scores\n",
    "    spacysim_arr: 1D array of spacy similarity scores\n",
    "    data_dict: list of dicts (women)\n",
    "    \n",
    "    returns: TUPLE!\n",
    "    \n",
    "    return_docs : list of dict with top 30 women (keys are name, summary, views)\n",
    "    \n",
    "    '''\n",
    "    cosine_used = True\n",
    "    spacy_used = True\n",
    "    if max(cossim_arr) == 0:\n",
    "        cosine_used = False\n",
    "    if max(spacysim_arr) == 0:\n",
    "        spacy_used = False\n",
    "    weighted_scores = cossim_arr*0.7 + spacysim_arr*0.3\n",
    "    sim_docs = np.argsort(weighted_scores)[::-1]\n",
    "    return_docs = []\n",
    "    for hit in sim_docs[0:30]:\n",
    "        return_docs.append(data_dict[hit])\n",
    "    return return_docs, cosine_used, spacy_used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([{u'name': u'Catherine Namono',\n",
       "   u'summary': u'Catherine Namono is an archaeologist that specializes in the study of Rock art in Uganda',\n",
       "   u'url': u'https://en.wikipedia.org/wiki/Catherine_Namono',\n",
       "   u'views': 1},\n",
       "  {u'name': u'Jenny Harrison',\n",
       "   u'summary': u'Jenny Harrison is a professor of mathematics at the University of California, Berkeley.',\n",
       "   u'url': u'https://en.wikipedia.org/wiki/Jenny_Harrison',\n",
       "   u'views': 10},\n",
       "  {u'name': u'Noriko Yui',\n",
       "   u'summary': u\"Noriko Yui is a professor of mathematics at Queen's University in Kingston, Ontario.\",\n",
       "   u'url': u'https://en.wikipedia.org/wiki/Noriko_Yui',\n",
       "   u'views': 4},\n",
       "  {u'name': u'Solveig Nordstr\\xf6m',\n",
       "   u'summary': u'Solveig Nordstr\\xf6m is a Swedish archeologist.',\n",
       "   u'url': u'https://en.wikipedia.org/wiki/Solveig_Nordstr%C3%B6m',\n",
       "   u'views': 1},\n",
       "  {u'name': u'Graciela Chichilnisky',\n",
       "   u'summary': u'Graciela Chichilnisky Is an Argentine American mathematical economist and an authority on climate change. She is a professor of economics at Columbia University.',\n",
       "   u'url': u'https://en.wikipedia.org/wiki/Graciela_Chichilnisky',\n",
       "   u'views': 25},\n",
       "  {u'name': u'Matilde Marcolli',\n",
       "   u'summary': u'Matilde Marcolli is an Italian mathematical physicist.',\n",
       "   u'url': u'https://en.wikipedia.org/wiki/Matilde_Marcolli',\n",
       "   u'views': 15},\n",
       "  {u'name': u'Maryanthe Malliaris',\n",
       "   u'summary': u'Maryanthe Elizabeth Malliaris is an associate professor of mathematics at the University of Chicago, a specialist in model theory.',\n",
       "   u'url': u'https://en.wikipedia.org/wiki/Maryanthe_Malliaris',\n",
       "   u'views': 12},\n",
       "  {u'name': u'Lynne H. Walling',\n",
       "   u'summary': u'Lynne H. Walling is a professor of mathematics at University of Bristol. She is known for her research in number theory.',\n",
       "   u'url': u'https://en.wikipedia.org/wiki/Lynne_H._Walling',\n",
       "   u'views': 1},\n",
       "  {u'name': u'Regula Tschumi',\n",
       "   u'summary': u'Regula Tschumi is a Swiss social anthropologist and art historian.',\n",
       "   u'url': u'https://en.wikipedia.org/wiki/Regula_Tschumi',\n",
       "   u'views': 1},\n",
       "  {u'name': u'Christel Rotthaus',\n",
       "   u'summary': u'Christel Rotthaus is a professor of mathematics at Michigan State University. She is known for her research in commutative algebra.',\n",
       "   u'url': u'https://en.wikipedia.org/wiki/Christel_Rotthaus',\n",
       "   u'views': 1},\n",
       "  {u'name': u'Antonella Grassi',\n",
       "   u'summary': u'Antonella Grassi is a mathematician specializing in algebraic geometry and string theory. She is a Fellow of the American Mathematical Society.',\n",
       "   u'url': u'https://en.wikipedia.org/wiki/Antonella_Grassi',\n",
       "   u'views': 2},\n",
       "  {u'name': u'Ortrud Oellermann',\n",
       "   u'summary': u'Ortrud R. Oellermann is a South African mathematician specializing in graph theory. She is a professor of mathematics at the University of Winnipeg.',\n",
       "   u'url': u'https://en.wikipedia.org/wiki/Ortrud_Oellermann',\n",
       "   u'views': 2},\n",
       "  {u'name': u'Shereen Ratnagar',\n",
       "   u'summary': u'Shereen F. Ratnagar is an Indian archaeologist whose work has focused on the Indus Valley Civilization. She is the author of several texts.',\n",
       "   u'url': u'https://en.wikipedia.org/wiki/Shereen_Ratnagar',\n",
       "   u'views': 7},\n",
       "  {u'name': u'Line Rochefort',\n",
       "   u'summary': u'Line Rochefort is a Canadian scientist specializing in peatland ecology.',\n",
       "   u'url': u'https://en.wikipedia.org/wiki/Line_Rochefort',\n",
       "   u'views': 1},\n",
       "  {u'name': u'Dana Angluin',\n",
       "   u'summary': u'Dana Angluin is a professor of computer science at Yale University. She contributed to the foundations of computational learning theory.',\n",
       "   u'url': u'https://en.wikipedia.org/wiki/Dana_Angluin',\n",
       "   u'views': 11},\n",
       "  {u'name': u'Natalia Berloff',\n",
       "   u'summary': u'Natalia G. Berloff is a professor of applied mathematics at the University of Cambridge. Her research includes the use of polaritons to simulate structures such as the classical XY model.',\n",
       "   u'url': u'https://en.wikipedia.org/wiki/Natalia_Berloff',\n",
       "   u'views': 4},\n",
       "  {u'name': u'Patricia Sawin',\n",
       "   u'summary': u'Patricia Sawin is an Associate Professor at the University of North Carolina at Chapel Hill. She is foremost an anthropologist and a folklorist on which she wrote a book called Listening for a Life [1].\\n\\n',\n",
       "   u'url': u'https://en.wikipedia.org/wiki/Patricia_Sawin',\n",
       "   u'views': 1},\n",
       "  {u'name': u'Maria-Carme Calderer',\n",
       "   u'summary': u'Maria-Carme Calderer is a professor of mathematics at University of Minnesota. Her research concerns applied mathematics.',\n",
       "   u'url': u'https://en.wikipedia.org/wiki/Maria-Carme_Calderer',\n",
       "   u'views': 3},\n",
       "  {u'name': u'Suzanne Weekes',\n",
       "   u'summary': u'Suzanne L. Weekes is a professor of Mathematical Sciences at Worcester Polytechnic Institute. She is a cofounder of the Mathematical Sciences Research Institute Undergraduate Program.',\n",
       "   u'url': u'https://en.wikipedia.org/wiki/Suzanne_Weekes',\n",
       "   u'views': 4},\n",
       "  {u'name': u'Laura Ferrarese',\n",
       "   u'summary': u'Laura Ferrarese is a researcher in space science at the National Research Council of Canada. Her primary work has been with the Hubble Space Telescope for space-based observations.',\n",
       "   u'url': u'https://en.wikipedia.org/wiki/Laura_Ferrarese',\n",
       "   u'views': 4},\n",
       "  {u'name': u'Rommie Amaro',\n",
       "   u'summary': u'Rommie E. Amaro is a professor of chemistry and biochemistry and the director of the National Biomedical Computation Resource at the University of California, San Diego. Her research focuses on development of computational methods in biophysics for applications to drug discovery.',\n",
       "   u'url': u'https://en.wikipedia.org/wiki/Rommie_Amaro',\n",
       "   u'views': 3},\n",
       "  {u'name': u'Mandy Chessell',\n",
       "   u'summary': u'Amanda Elizabeth Chessell CBE, FREng is a computer scientist and a Distinguished Engineer at IBM. She has been awarded the title of IBM Master Inventor. She is also a Member of the IBM Academy of Technology.\\nOutside IBM, Chessell is the first woman to be awarded the Silver Medal of the Royal Academy of Engineering. In 2002 she was elected a Fellow of the Royal Academy of Engineering.\\nChessell is a visiting professor at the University of Sheffield and at the Surrey Centre for the Digital Economy (CoDE) at the University of Surrey.',\n",
       "   u'url': u'https://en.wikipedia.org/wiki/Mandy_Chessell',\n",
       "   u'views': 4},\n",
       "  {u'name': u'Juliet Morrow',\n",
       "   u'summary': u'Juliet Morrow is an American archaeologist and a professor of Anthropology at Arkansas State University in Jonesboro, Arkansas.',\n",
       "   u'url': u'https://en.wikipedia.org/wiki/Juliet_Morrow',\n",
       "   u'views': 1},\n",
       "  {u'name': u'Dolores Piperno',\n",
       "   u'summary': u'Dolores Piperno is an American archaeologist specializing in archaeobotany. She is a staff scientist emeritus of the Smithsonian Tropical Research Institute in Balboa, Panama.\\n\\n',\n",
       "   u'url': u'https://en.wikipedia.org/wiki/Dolores_Piperno',\n",
       "   u'views': 3},\n",
       "  {u'name': u'Jessica Hammer',\n",
       "   u'summary': u'Jessica Hammer is an assistant professor in the Human-Computer Interaction Institute at Carnegie Mellon University.\\n\\n',\n",
       "   u'url': u'https://en.wikipedia.org/wiki/Jessica_Hammer',\n",
       "   u'views': 4},\n",
       "  {u'name': u'Annie Selden',\n",
       "   u'summary': u'Annie Laurer Alexander Selden is an expert in mathematics education. She is a professor emeritus at Tennessee Technological University, and an adjunct professor at New Mexico State University. She was one of the original founders of the Association for Women in Mathematics in 1971.',\n",
       "   u'url': u'https://en.wikipedia.org/wiki/Annie_Selden',\n",
       "   u'views': 1},\n",
       "  {u'name': u'Therese Biedl',\n",
       "   u'summary': u'Therese Charlotte Biedl is an Austrian computer scientist known for her research in computational geometry and graph drawing. Currently she is a professor at the University of Waterloo in Canada.',\n",
       "   u'url': u'https://en.wikipedia.org/wiki/Therese_Biedl',\n",
       "   u'views': 1},\n",
       "  {u'name': u'Carolyn Hamilton',\n",
       "   u'summary': u\"Dame Carolyn Paula Hamilton DBE (born November 1951) is a barrister who specialises in children's rights. She is also director of Coram Children's Legal Centre, an independent national charity dedicated to the promotion and implementation of children's rights based at the University of Essex. Hamilton has the position of professor at Essex.\",\n",
       "   u'url': u'https://en.wikipedia.org/wiki/Carolyn_Hamilton',\n",
       "   u'views': 3},\n",
       "  {u'name': u'Shannon Lee Dawdy',\n",
       "   u'summary': u'Shannon Lee Dawdy is an American historian, archeologist and anthropologist. She is an associate professor at the University of Chicago and a MacArthur Fellow.',\n",
       "   u'url': u'https://en.wikipedia.org/wiki/Shannon_Lee_Dawdy',\n",
       "   u'views': 5},\n",
       "  {u'name': u'Lori A. Clarke',\n",
       "   u'summary': u'Lori A. Clarke is an American computer scientist noted for her research on software engineering.',\n",
       "   u'url': u'https://en.wikipedia.org/wiki/Lori_A._Clarke',\n",
       "   u'views': 2}],\n",
       " False,\n",
       " True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = u\"is a BAMF\"\n",
    "s = spacysim_scores(spacy_array, query, deduped_women)\n",
    "c = cossim_scores(vectorizer, matx, query, deduped_women)\n",
    "return_query(c, s, deduped_women)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
